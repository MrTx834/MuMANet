################################################################################
# training parameters
################################################################################
train:
  pipeline: "MuMANet"  # model name
  loss: "xentropy"       # must be either xentropy or iou
  max_epochs: 50
  batch_size: 2          # batch size
  report_batch: 10       # every x batches, report loss
  report_epoch: 1        # every x epochs, report validation set
  epsilon_w: 0.001       # class weight w = 1 / (content + epsilon_w)
  save_summary: False    # Summary of weight histograms for tensorboard
  save_scans: False      # False doesn't save anything, True saves some sample images 
                         # (one per batch of the last calculated batch) in log folder
  show_scans: False      # show scans during training
  workers: 12            # number of threads to get data
  syncbn: True           # sync batchnorm
  act: SiLU               # act layer, LeakyReLU, SiLU, Hardswish, GELU
  optimizer: "adam"  # sgd or adam
  scheduler: "consine"  # "consine" or "warmup"
  consine:
    min_lr: 0.00001
    max_lr: 0.00200
    first_cycle: 50
    cycle: 2
    wup_epochs: 1
    gamma: 1.0
  warmup:
    lr: 0.01             # learning rate
    wup_epochs: 1        # warmup during first XX epochs (can be float)
    lr_decay: 0.99       # learning rate decay per epoch after initial cycle (from min lr)
    momentum: 0.9          # sgd momentum
  aux_loss:
    use: True
    lamda: [1.0, 1.0, 1.0, 1.0]
  residual: False # This needs to be the same as in the dataset params below!
  n_input_scans: 2 # This needs to be the same as in the dataset params below!
  input_depth:
    range: True
    xyz: True
    remission: True
post:
  CRF:
    use: False
    train: True
    params: False # this should be a dict when in use
  KNN:
    use: True # This parameter default is false
    params:
      knn: 7
      search: 7
      sigma: 1.0
      cutoff: 2.0
################################################################################
# classification head parameters
################################################################################
# dataset (to find parser)
dataset:
  labels: "kitti"
  scans: "kitti"
  max_points: 150000 # max of any scan in dataset
  sensor:
    name: "HDL64"
    type: "spherical" # projective
    fov_up: 3
    fov_down: -25
    img_prop:
      width:  2048
      height: 64
    img_means: #range,x,y,z,signal
      - 11.71279
      - -0.1023471
      - 0.4952
      - -1.0545
      - 0.2877
    img_stds: #range,x,y,z,signal
      - 10.24
      - 12.295865
      - 9.4287
      - 0.8643
      - 0.1450
    # img_means: #range,x,y,z,signal
    #   - 12.12
    #   - 10.88
    #   - 0.23
    #   - -1.04
    #   - 0.21
    # img_stds: #range,x,y,z,signal
    #   - 12.32
    #   - 11.47
    #   - 6.91
    #   - 0.86
    #   - 0.16
    # for mos
    n_input_scans: 2  # This needs to be the same as in the backbone params above!
    residual: False # This needs to be the same as in the backbone params above!
    transform: True  # tranform the last n_input_scans - 1 frames before concatenation
    use_normal: False # if use normal vector as channels of range image